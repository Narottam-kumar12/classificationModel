Setiment Analysis System

ðŸ§  Overview

This project implements a robust Sentiment Analysis System built using a fine-tuned DistilBERT model. 
It classifies text reviews as positive or negative, with an intelligent self-correcting fallback mechanism for ambiguous or low-confidence predictions.
This system is ideal for applications requiring real-time sentiment feedback with user interaction and correction for improved accuracy.

âœ… Features

  ðŸ” Sentiment Classification :   Detects positive or negative sentiment in English reviews.

  âš–ï¸ Confidence Thresholding :    Flags predictions with low confidence for review.

  ðŸ™‹ User Clarification Loop :    Allows human-in-the-loop correction for uncertain predictions.

  ðŸ§¾ Logging :                    Records predictions, confidences, and user corrections.

  ðŸ’» Interactive CLI :            Command-line interface for user testing and feedback.

   âš™ï¸ Customizable Settingsn :      Easily configurable model and logging parameters.

Install dependencies
pip install -r requirements.txt

ðŸ’¬ Sample Interaction:

Enter a review: I love this product!

Predicted sentiment: Positive | Confidence: 0.98

Enter a review: It was okay

âš ï¸ Low confidence prediction (0.55)

âš ï¸ Potential incorrect sentiment detected!

Model predicted: Positive

Review text: 'It was okay'

Was this correct? (yes/no):

Your answer: no

Please clarify your review: It was mediocre

âœ… Final sentiment: Negative

ðŸ—‚ï¸ File Structure

classificationModel/

â”œâ”€â”€ main.py                   # Main CLI interface

â”œâ”€â”€ inference_node.py         # Model prediction logic

â”œâ”€â”€ confidence_check_node.py  # Handles threshold validation

â”œâ”€â”€ fallback_node.py          # Collects user feedback

â”œâ”€â”€ custom_logger.py          # Logging module

â”œâ”€â”€ config.py                 # Configuration parameters

â”œâ”€â”€ requirements.txt          # Dependencies

â””â”€â”€ logs/                     # Logged predictions and feedback

ðŸ§¬ Model Specifications

.........................................................................................................

Parameter --->	Value

Base Model --->	distilbert-base-uncased-finetuned-sst-2-english

Training Dataset --->	Stanford Sentiment Treebank (SST-2)

Accuracy  --->	~91.3% on test data

Max Tokens --->	512

Avg. Inference --->	~50ms per review (on CPU)

.........................................................................................................

ðŸ“ˆ Performance

âœ… Strong Reviews (clear positive/negative): ~98% accurate

âš ï¸ Ambiguous Reviews (neutral, mixed tone): ~72% accurate

     - Triggers fallback for:
     
    -  Neutral phrases: "It was okay"
    
    - Mixed sentiment: "Good but not great"

    
    -   Negations    : "Not bad"


ðŸš« Limitations

ðŸŒ Only supports English language

ðŸ˜… Struggles with sarcasm, irony, and complex negations

ðŸ“¦ No batch processing (yet)

ðŸ“Š No dashboard or visual analytics

..............................................................................

ðŸ”® Future Enhancements

ðŸŒ Multi-language support

ðŸ˜ Add neutral sentiment classification

ðŸŒ Web-based front-end with Flask/Streamlit

ðŸ” Auto model retraining with user feedback

ðŸ“Š Sentiment intensity scoring (very positive â†’ very negative)

#Demo video

link ---> https://drive.google.com/file/d/1Xhb2EDrahEusn3U6AYG2Z2Q_WzSv6Io-/view?usp=drivesdk



